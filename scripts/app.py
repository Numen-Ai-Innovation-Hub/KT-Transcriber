"""Interface Streamlit para busca semÃ¢ntica KT Transcriber.

Conecta ao FastAPI local via HTTP para executar o pipeline RAG de busca
sobre transcriÃ§Ãµes de reuniÃµes KT. NÃ£o importa de src/ â€” consome apenas
endpoints HTTP.

O pipeline RAG Ã© executado de forma transparente em 6 estÃ¡gios via ARQ,
exibindo o progresso em tempo real via st.progress().

Uso:
    streamlit run scripts/app.py

Exemplo:
    .venv\\Scripts\\streamlit.exe run scripts/app.py --server.port 8501
"""

import os
import time

import requests
import streamlit as st
from dotenv import load_dotenv

load_dotenv()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURAÃ‡ÃƒO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

FASTAPI_URL: str = os.getenv("FASTAPI_URL", "http://localhost:8000")
SEARCH_ENDPOINT: str = f"{FASTAPI_URL}/v1/kt-search/"
INDEXING_STATUS_ENDPOINT: str = f"{FASTAPI_URL}/v1/kt-indexing/status"
HEALTH_ENDPOINT: str = f"{FASTAPI_URL}/v1/health"

PIPELINE_START_ENDPOINT: str = f"{FASTAPI_URL}/v1/kt-search/pipeline/start"
PIPELINE_STAGE_ENDPOINT: str = f"{FASTAPI_URL}/v1/kt-search/pipeline/{{session_id}}/{{stage}}"
PIPELINE_STATUS_ENDPOINT: str = f"{FASTAPI_URL}/v1/kt-search/pipeline/status/{{job_id}}"
PIPELINE_RESULT_ENDPOINT: str = f"{FASTAPI_URL}/v1/kt-search/pipeline/{{session_id}}/result"

QUERY_TYPE_LABELS: dict[str, str] = {
    "SEMANTIC": "SemÃ¢ntica",
    "METADATA": "Metadados",
    "ENTITY": "Entidade",
    "TEMPORAL": "Temporal",
    "CONTENT": "ConteÃºdo",
    "EARLY_EXIT": "Cliente nÃ£o encontrado",
}

# EstÃ¡gios do pipeline: (nome_endpoint, nome_task_display)
# O primeiro estÃ¡gio (enrich) Ã© enfileirado pelo /start â€” nÃ£o tem endpoint prÃ³prio
PIPELINE_STAGES: list[tuple[str | None, str]] = [
    (None, "Enriquecimento da query"),
    ("classify", "ClassificaÃ§Ã£o do tipo RAG"),
    ("chromadb", "Busca ChromaDB"),
    ("discover", "Descoberta de clientes"),
    ("select", "SeleÃ§Ã£o de chunks"),
    ("insights", "GeraÃ§Ã£o de insights (GPT)"),
]

_POLL_INTERVAL_S = 1.0
_POLL_TIMEOUT_S = 120.0


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PÃGINA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.set_page_config(
    page_title="KT Transcriber â€” Busca",
    page_icon="ğŸ”",
    layout="wide",
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Sidebar
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with st.sidebar:
    st.title("KT Transcriber")
    st.caption("Busca semÃ¢ntica em transcriÃ§Ãµes de reuniÃµes KT")

    st.divider()

    # Status da API
    st.subheader("Status da API")
    try:
        health = requests.get(HEALTH_ENDPOINT, timeout=2)
        if health.status_code == 200:
            st.success("FastAPI: online")
        else:
            st.error(f"FastAPI: erro {health.status_code}")
    except requests.exceptions.ConnectionError:
        st.error("FastAPI: offline")
        st.info("Inicie a stack com start-services.bat")

    st.divider()

    # Status do Ã­ndice
    st.subheader("Ãndice ChromaDB")
    try:
        idx = requests.get(INDEXING_STATUS_ENDPOINT, timeout=3)
        if idx.status_code == 200:
            data = idx.json()
            st.metric("Documentos indexados", data.get("total_documents", 0))
            st.metric("ColeÃ§Ã£o", data.get("collection_name", "â€”"))
            clientes = data.get("unique_clients", [])
            if clientes:
                st.caption("Clientes:")
                for c in clientes:
                    st.caption(f"â€¢ {c}")
        else:
            st.warning("Ãndice indisponÃ­vel")
    except requests.exceptions.ConnectionError:
        st.warning("FastAPI offline â€” status do Ã­ndice indisponÃ­vel")
    except Exception as exc:
        st.warning(f"NÃ£o foi possÃ­vel obter status do Ã­ndice: {exc}")

    st.divider()
    st.caption("[Swagger UI](http://localhost:8000/docs)")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ãrea principal
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.title("ğŸ” Busca em ReuniÃµes KT")
st.caption("FaÃ§a perguntas em linguagem natural sobre as transcriÃ§Ãµes indexadas.")

query = st.text_input(
    label="Sua pergunta",
    placeholder="Ex: Quais mÃ³dulos SAP foram discutidos? Quais decisÃµes foram tomadas sobre integraÃ§Ã£o?",
    help="MÃ­nimo 3 caracteres. A busca usa pipeline RAG com ChromaDB + GPT.",
)

buscar = st.button("Buscar", type="primary", use_container_width=False)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HELPERS DE EXECUÃ‡ÃƒO DO PIPELINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def _poll_until_ready(job_id: str, stage_label: str) -> bool:
    """Faz polling do status de um job ARQ atÃ© completar ou timeout.

    Args:
        job_id: ID do job ARQ a aguardar.
        stage_label: Nome do estÃ¡gio para mensagens de erro.

    Returns:
        True se o job completou com stage_ready=True. False em caso de falha ou timeout.
    """
    deadline = time.time() + _POLL_TIMEOUT_S
    while time.time() < deadline:
        try:
            resp = requests.get(
                PIPELINE_STATUS_ENDPOINT.format(job_id=job_id),
                timeout=5,
            )
            if resp.status_code != 200:
                st.error(f"Erro ao consultar status do estÃ¡gio '{stage_label}': HTTP {resp.status_code}")
                return False

            data = resp.json()
            arq_status: str = data.get("arq_status", "")

            if arq_status == "failed":
                st.error(f"Falha no estÃ¡gio '{stage_label}': {data.get('error', 'sem detalhes')}")
                return False

            if arq_status == "complete" and data.get("stage_ready"):
                return True

        except requests.exceptions.ConnectionError:
            st.error("ConexÃ£o com FastAPI perdida durante execuÃ§Ã£o do pipeline.")
            return False
        except requests.exceptions.Timeout:
            pass  # Continua tentando

        time.sleep(_POLL_INTERVAL_S)

    st.error(f"Timeout: o estÃ¡gio '{stage_label}' demorou mais de {_POLL_TIMEOUT_S:.0f}s.")
    return False


def _run_pipeline(query_text: str) -> dict | None:
    """Executa o pipeline RAG de 6 estÃ¡gios com barra de progresso em tempo real.

    Args:
        query_text: Query do usuÃ¡rio.

    Returns:
        Dict com o resultado final (compatÃ­vel com KTSearchResponse) ou None em caso de falha.
    """
    total = len(PIPELINE_STAGES)
    progress = st.progress(0.0, text="Iniciando pipeline...")

    # â”€â”€ Fase 1: start + enrich (enfileirado automaticamente pelo /start)
    _, stage_label = PIPELINE_STAGES[0]
    progress.progress(0.0, text=f"â³ {stage_label}...")

    try:
        resp = requests.post(PIPELINE_START_ENDPOINT, json={"query": query_text}, timeout=10)
        if resp.status_code != 200:
            progress.progress(0.0, text="âŒ Falha ao iniciar pipeline")
            st.error(f"Falha ao iniciar pipeline: HTTP {resp.status_code}")
            return None
        start_data = resp.json()
    except requests.exceptions.ConnectionError:
        progress.progress(0.0, text="âŒ Sem conexÃ£o com FastAPI")
        st.error("NÃ£o foi possÃ­vel conectar ao FastAPI.")
        return None

    session_id: str = start_data["session_id"]
    job_id: str = start_data["job_id"]

    if not _poll_until_ready(job_id, stage_label):
        progress.progress(0.0, text=f"âŒ Falha: {stage_label}")
        return None

    progress.progress(1 / total, text=f"âœ… {stage_label}")

    # â”€â”€ Fases 2â€“6: cada uma enfileirada apÃ³s a anterior completar
    for i, (stage_endpoint, stage_label) in enumerate(PIPELINE_STAGES[1:], start=1):
        progress.progress(i / total, text=f"â³ {stage_label}...")

        try:
            resp = requests.post(
                PIPELINE_STAGE_ENDPOINT.format(session_id=session_id, stage=stage_endpoint),
                timeout=10,
            )
            if resp.status_code != 200:
                progress.progress(i / total, text=f"âŒ Falha: {stage_label}")
                st.error(f"Falha ao enfileirar '{stage_label}': HTTP {resp.status_code}")
                return None
            stage_data = resp.json()
        except requests.exceptions.ConnectionError:
            progress.progress(i / total, text="âŒ Sem conexÃ£o com FastAPI")
            st.error("NÃ£o foi possÃ­vel conectar ao FastAPI.")
            return None

        job_id = stage_data["job_id"]
        if not _poll_until_ready(job_id, stage_label):
            # Verifica se houve early-exit (resultado final jÃ¡ disponÃ­vel)
            result_resp = requests.get(PIPELINE_RESULT_ENDPOINT.format(session_id=session_id), timeout=5)
            if result_resp.status_code == 200:
                progress.progress(1.0, text="âœ… Pipeline concluÃ­do")
                return result_resp.json()
            progress.progress(i / total, text=f"âŒ Falha: {stage_label}")
            return None

        progress.progress((i + 1) / total, text=f"âœ… {stage_label}")

    progress.progress(1.0, text="âœ… Pipeline concluÃ­do")

    # â”€â”€ LÃª resultado final
    result_resp = requests.get(PIPELINE_RESULT_ENDPOINT.format(session_id=session_id), timeout=10)
    if result_resp.status_code == 200:
        return result_resp.json()

    st.error("Resultado final indisponÃ­vel apÃ³s conclusÃ£o do pipeline.")
    return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXECUÃ‡ÃƒO DA BUSCA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if buscar:
    if not query or len(query.strip()) < 3:
        st.warning("Digite pelo menos 3 caracteres para buscar.")
    else:
        result = _run_pipeline(query.strip())

        if result is not None:
            # MÃ©tricas
            col1, col2, col3 = st.columns(3)
            query_type_raw = result.get("query_type", "")
            query_type_label = QUERY_TYPE_LABELS.get(query_type_raw, query_type_raw)
            col1.metric("Tipo de consulta", query_type_label)
            col2.metric("Contextos encontrados", len(result.get("contexts", [])))
            col3.metric("Tempo de processamento", f"{result.get('processing_time', 0):.2f}s")

            st.divider()

            # Resposta principal
            st.subheader("Resposta")
            answer = result.get("answer", "")
            if answer:
                st.markdown(answer)
            else:
                st.info("Nenhuma resposta gerada. Verifique se hÃ¡ documentos indexados.")

            # Contextos
            contexts = result.get("contexts", [])
            if contexts:
                st.divider()
                section_title = "VÃ­deos disponÃ­veis" if query_type_raw == "METADATA" else "Contextos relevantes"
                st.subheader(f"{section_title} ({len(contexts)})")
                for i, ctx in enumerate(contexts):
                    video = ctx.get("video_name", f"Contexto {i + 1}")
                    speaker = ctx.get("speaker", "")
                    label = f"ğŸ“„ {video}" + (f" â€” {speaker}" if speaker else "")
                    with st.expander(label, expanded=(i == 0)):
                        doc = ctx.get("content", "")
                        if doc:
                            st.markdown(doc)
                        client = ctx.get("client", "")
                        timestamp = ctx.get("timestamp", "")
                        url = ctx.get("original_url", "")
                        if client:
                            st.caption(f"Cliente: {client}")
                        if timestamp and timestamp not in ("Unknown", "", "00:00-00:00"):
                            st.caption(f"Tempo: {timestamp}")
                        if url:
                            st.markdown(f"[Assistir no TL:DV]({url})")
