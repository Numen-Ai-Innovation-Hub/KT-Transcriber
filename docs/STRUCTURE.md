# Estrutura do Projeto ‚Äî KT-Transcriber

Documenta√ß√£o da estrutura de pastas e arquivos do projeto. Gerado por `/document-project`.

---

## `src/` ‚Äî C√≥digo-fonte principal

### `src/api/` ‚Äî Camada HTTP: routers, schemas e aplica√ß√£o FastAPI

- **`main.py`** ‚Äî Aplica√ß√£o FastAPI: lifespan (startup/shutdown), registro de routers, handlers globais de exce√ß√£o (ApplicationError, RequestValidationError, Exception), configura√ß√£o de CORS e ARQ pool
- **`routers/`** ‚Äî Endpoints HTTP organizados por dom√≠nio
  - **`health.py`** ‚Äî `GET /v1/health` ‚Äî retorna status da API e vers√£o
  - **`kt_ingestion_router.py`** ‚Äî `POST /v1/kt-ingestion/run` (enfileira task) e `GET /v1/kt-ingestion/status/{job_id}` (polling)
  - **`kt_indexing_router.py`** ‚Äî `POST /v1/kt-indexing/run` (enfileira task), `GET /v1/kt-indexing/status` (info ChromaDB), `GET /v1/kt-indexing/status/{job_id}` (polling)
  - **`kt_search_router.py`** ‚Äî `POST /v1/kt-search/` (busca s√≠ncrona) e pipeline ass√≠ncrono de 6 est√°gios (`/pipeline/start`, `/pipeline/{session_id}/classify`, `/pipeline/{session_id}/chromadb`, `/pipeline/{session_id}/discover`, `/pipeline/{session_id}/select`, `/pipeline/{session_id}/insights`, `/pipeline/status/{job_id}`, `/pipeline/{session_id}/result`)
  - **`kt_pipeline_router.py`** ‚Äî `GET /v1/kt-pipeline/meetings` (lista reuni√µes TL:DV com badge `already_indexed`), `POST /v1/kt-pipeline/start` (enfileira pipeline seletivo), `GET /v1/kt-pipeline/status/{job_id}` (polling)
- **`schemas/`** ‚Äî Schemas Pydantic para toda a API
  - **`kt_schemas.py`** ‚Äî Todos os schemas de request/response: `KTSearchRequest`, `KTSearchResponse`, `AsyncJobResponse`, `JobStatusResponse`, `KTIndexingStatusResponse`, `PipelineStartRequest`, `PipelineStartResponse`, `StageJobResponse`, `StageStatusResponse`, `MeetingItemResponse`, `MeetingListResponse`, `SelectivePipelineRequest`, `SelectivePipelineStartResponse`

### `src/config/` ‚Äî Configura√ß√£o da aplica√ß√£o

- **`settings.py`** ‚Äî √önica fonte de verdade para paths e vari√°veis de ambiente: `DIRECTORY_PATHS` (sqlite_db, vector_db, transcriptions), `FILE_PATHS` (hashes_db), constantes de formata√ß√£o (`DELIMITER_LINE`, `DELIMITER_SECTION`), vari√°veis lidas do `.env` (Redis, TL:DV, OpenAI, ChromaDB, app)
- **`startup.py`** ‚Äî Side effects de inicializa√ß√£o: `initialize_application()` (orquestra diret√≥rios + logging), `ensure_directories_exist()` (cria `data/` e subpastas), `setup_logging()` (arquivo rotativo di√°rio + console, silencia libs verbosas)

### `src/helpers/` ‚Äî Fun√ß√µes auxiliares transversais ao projeto

- **`kt_helpers.py`** ‚Äî `build_meeting_key()`, `build_job_key()`, `extract_video_name_from_path()` ‚Äî constroem chaves padronizadas para Redis e extraem nomes limpos de caminhos

### `src/kt_ingestion/` ‚Äî Dom√≠nio: download e consolida√ß√£o de transcri√ß√µes do TL:DV

- **`tldv_client.py`** ‚Äî `TLDVClient`: comunica√ß√£o com API TL:DV ‚Äî lista reuni√µes, obt√©m transcri√ß√£o com polling, retorna `MeetingData` estruturado; dataclasses: `MeetingData`, `TranscriptSegment`, `Highlight`; enum: `MeetingStatus`
- **`smart_processor.py`** ‚Äî `SmartMeetingProcessor`: processa reuni√£o em duas fases (dados imediatos + completude em background thread); flag `is_complete` para valida√ß√£o antes de salvar
- **`json_consolidator.py`** ‚Äî `JSONConsolidator`: cria JSON consolidado no formato aninhado (`metadata` + `transcript.segments` + `highlights`) e salva em `data/transcriptions/`
- **`kt_ingestion_constants.py`** ‚Äî Constantes: endpoints TL:DV (`TLDV_MEETINGS_ENDPOINT`, `TLDV_IMPORTS_ENDPOINT`), timeouts (`TLDV_MAX_WAIT_SECONDS=300`, `TLDV_POLL_INTERVAL_SECONDS=10`), limites de threads (`MAX_BACKGROUND_THREADS=5`)

### `src/kt_indexing/` ‚Äî Dom√≠nio: chunking, embedding e indexa√ß√£o no ChromaDB

- **`indexing_engine.py`** ‚Äî `IndexingEngine`: orquestra o processamento completo de um JSON ‚Äî normaliza√ß√£o de nome, chunking por segmento, extra√ß√£o de metadados via LLM e gera√ß√£o de embeddings ‚Äî com suporte a processamento em lote de todos os JSONs novos
- **`chromadb_store.py`** ‚Äî `ChromaDBStore`: persist√™ncia e busca vetorial via ChromaDB PersistentClient; `EmbeddingGenerator`: gera embeddings h√≠bridos via OpenAI (80% conte√∫do + 20% metadados)
- **`video_normalizer.py`** ‚Äî `EnhancedVideoNormalizer`: normaliza nome de reuni√£o e gera slug sem√¢ntico no formato `{cliente}_{modulo_ou_keyword}_{data}` (ex: `dexco_ewm_20250822`); usa LLM como fallback
- **`text_chunker.py`** ‚Äî `TextChunker`: divide segmentos de transcri√ß√£o em chunks de at√© 1000 chars com sobreposi√ß√£o de 200 chars; dataclass `ChunkPart` (text, char_start, char_end, part_index, total_parts)
- **`llm_metadata_extractor.py`** ‚Äî `LLMMetadataExtractor`: extrai via GPT-4o-mini metadados estruturados de cada chunk: `meeting_phase`, `kt_type`, `sap_modules`, `transactions`, `technical_terms`, `participants_mentioned`, `systems`, `decisions`, `problems`, `searchable_tags`
- **`file_generator.py`** ‚Äî `FileGenerator`: cria arquivos TXT de auditoria em `data/transcriptions/chunks/` com metadados TL:DV, metadados LLM e conte√∫do do chunk
- **`kt_indexing_utils.py`** ‚Äî Fun√ß√µes utilit√°rias: `load_and_validate_json()`, `extract_client_name_smart()` (prioridade: `[BRACKET]` ‚Üí client_patterns ‚Üí fallback `"DEXCO"`), `extract_sap_modules_from_title()`, `extract_enriched_tldv_fields()`, `normalize_client_name()`
- **`kt_indexing_constants.py`** ‚Äî Constantes: `CHUNK_CONFIG` (max_chars, overlap, min), `LLM_CONFIG` (modelo, retries, temperatura), `CHROMADB_CONFIG` (collection, dimens√µes), `KT_TYPE_PATTERNS` (sustentacao, implementacao, treinamento...), `METADATA_LIMITS`

### `src/kt_search/` ‚Äî Dom√≠nio: pipeline RAG de 5 est√°gios para busca sem√¢ntica

- **`search_engine.py`** ‚Äî `SearchEngine`: orquestra pipeline RAG completo em modo s√≠ncrono (instancia todos os 7 componentes; m√©todo `search()` executa est√°gios em sequ√™ncia)
- **`query_enricher.py`** ‚Äî `QueryEnricher`: detecta entidades (clientes, transa√ß√µes SAP, m√≥dulos, participantes, temporal), normaliza e expande query; retorna `EnrichmentResult`
- **`query_classifier.py`** ‚Äî `QueryClassifier`: classifica tipo de busca RAG em `SEMANTIC | METADATA | ENTITY | TEMPORAL | CONTENT` com confidence e fallbacks; retorna `ClassificationResult`
- **`query_type_detector.py`** ‚Äî `QueryTypeDetector`: detecta (sem LLM/ChromaDB) se query √© an√°lise de KT espec√≠fico (`detect_specific_kt_analysis()`) ou listagem gen√©rica (fast-track)
- **`chromadb_search_executor.py`** ‚Äî `ChromaDBSearchExecutor`: executa 5 estrat√©gias de busca no ChromaDB (SEMANTIC, METADATA, ENTITY, TEMPORAL, CONTENT) com early-exit para cliente inexistente
- **`dynamic_client_manager.py`** ‚Äî `DynamicClientManager`: descobre clientes √∫nicos presentes no ChromaDB com contagem; filtra resultados por cliente relevante √† query
- **`chunk_selector.py`** ‚Äî `ChunkSelector`: scoring de qualidade + diversidade para sele√ß√£o de TOP-K chunks adaptativos ao tipo de query; dataclasses `ChunkScore`, `SelectionResult`
- **`insights_agent.py`** ‚Äî `InsightsAgent`: gera resposta final via GPT analisando m√∫ltiplos contextos selecionados; consolida insights acion√°veis; retorna `DirectInsightResult`
- **`insights_prompts.py`** ‚Äî Fun√ß√µes para constru√ß√£o de prompts: `get_insights_extraction_prompt()`, `get_final_answer_prompt()`, `get_summary_prompt()`
- **`insight_processors.py`** ‚Äî Processadores de insights p√≥s-gera√ß√£o: consolida√ß√£o, deduplica√ß√£o e ranqueamento de insights extra√≠dos
- **`search_response_builder.py`** ‚Äî `SearchResponseBuilder`: monta `SearchResponse` final com metadados; detecta cliente inexistente (`should_stop_for_nonexistent_client()`); analisa complexidade da query
- **`search_types.py`** ‚Äî Tipos do dom√≠nio de busca: `SearchResponse` (intelligent_response, contexts, summary_stats, query_type, processing_time, success, error_message); `QueryType` enum
- **`search_formatters.py`** ‚Äî Formata√ß√£o de resultados para console: `print_results()`, `format_contexts()`, `format_summary_stats()`
- **`search_cli.py`** ‚Äî CLI de busca: `run_interactive_search()` (loop REPL), `run_single_search(query)` (busca √∫nica com sa√≠da)
- **`search_logging.py`** ‚Äî `PipelineLogger`: log estruturado de cada est√°gio do pipeline (nome, status, dura√ß√£o, detalhes)
- **`search_utils.py`** ‚Äî Utilit√°rios: `normalize_query()`, `calculate_relevance_score()`, `extract_top_entities()`
- **`kt_search_constants.py`** ‚Äî Constantes: `ENTITY_PATTERNS` (regex para clientes/transa√ß√µes/m√≥dulos), `QUERY_PATTERNS` (detec√ß√£o de tipo RAG), `QUALITY_WEIGHTS`, `DIVERSITY_CONFIG`, `TOP_K_STRATEGY` (adaptativo por tipo)

### `src/services/` ‚Äî Singletons thread-safe de orquestra√ß√£o

- **`kt_ingestion_service.py`** ‚Äî `KTIngestionService`: singleton que orquestra TLDVClient + SmartMeetingProcessor + JSONConsolidator; m√©todos: `force_clean()`, `run_ingestion()`, `list_meetings_with_status()`, `run_selective_ingestion(meeting_ids)`
- **`kt_indexing_service.py`** ‚Äî `KTIndexingService`: singleton que orquestra IndexingEngine + ChromaDBStore; m√©todos: `force_clean()` (apaga ChromaDB + chunks/), `run_indexing()`, `get_status()`
- **`kt_search_service.py`** ‚Äî `KTSearchService`: singleton que orquestra SearchEngine; m√©todo `search(query)` e propriedade `components` (exp√µe os 7 componentes individuais para tasks ARQ)
- **`llm_service.py`** ‚Äî Ponto √∫nico de re-export do `utils/llm_manager.py`: `LLMUsageTrackingCallback`, `get_structured_output_method`, `llm_client_manager`, `llm_monitor`

### `src/tasks/` ‚Äî Tasks ARQ ass√≠ncronas

- **`arq_worker.py`** ‚Äî `WorkerSettings`: `max_jobs=6`, `job_timeout=7200`, `keep_result=3600`, `poll_delay=0.5`; lista de 10 functions registradas; callbacks `startup()` e `shutdown()`
- **`kt_ingestion_task.py`** ‚Äî `kt_ingestion_task(ctx)`: download incremental de reuni√µes TL:DV; lazy import de `get_kt_ingestion_service()`
- **`kt_indexing_task.py`** ‚Äî `kt_indexing_task(ctx)`: indexa√ß√£o incremental de JSONs no ChromaDB; lazy import de `get_kt_indexing_service()`
- **`kt_selective_pipeline_task.py`** ‚Äî `kt_selective_pipeline_task(ctx, meeting_ids, session_id, force_clean)`: pipeline completo seletivo ‚Äî `force_clean` opcional + ingestion seletiva + indexa√ß√£o
- **`kt_search_task.py`** ‚Äî 6 tasks do pipeline RAG ass√≠ncrono, cada uma l√™/escreve estado no Redis via `ctx["redis"]`: `kt_search_enrich_task`, `kt_search_classify_task`, `kt_search_chromadb_task`, `kt_search_discover_task`, `kt_search_select_task`, `kt_search_insights_task`

---

## `utils/` ‚Äî Utilit√°rios port√°veis (zero depend√™ncias de `src/`)

- **`exception_setup.py`** ‚Äî `ApplicationError(Exception)`: exception padr√£o do time com `message`, `status_code`, `error_code` (VALIDATION_ERROR, NOT_FOUND, SERVICE_UNAVAILABLE, QUOTA_EXCEEDED, INTERNAL_ERROR), `context` (dict para debug) e `timestamp` (UTC)
- **`logger_setup.py`** ‚Äî `LoggerManager`: `get_logger(name)`, `setup_logging()`, `set_default_log_dir()`; formato `TIMESTAMP [logger_name] [LEVEL] message`; idempotente (n√£o duplica handlers); silencia libs verbosas
- **`hash_manager.py`** ‚Äî `HashManager`: cache de hashes por conte√∫do em SQLite (`data/sqlite_db/hashes.db`); m√©todos: `generate_file_hash()`, `should_reprocess()`, `update_cache_hash()`, `load_hash_metadata()`
- **`llm_manager.py`** ‚Äî `LLMManager`: cliente LLM multi-provider (OpenAI, Gemini, Anthropic, Ollama) com tracking de uso (`LLMUsageTrackingCallback`), retries e timeout; `llm_client_manager` (singleton), `llm_monitor`
- **`string_helpers.py`** ‚Äî `sanitize_string()`, `truncate_string()`, `normalize_whitespace()` ‚Äî manipula√ß√£o gen√©rica de strings
- **`pdfplumber_extractor.py`** ‚Äî `PDFPlumberExtractor`: `extract_text(pdf_path)`, `extract_tables(pdf_path)` ‚Äî extra√ß√£o simples de texto e tabelas de PDFs
- **`dpt2_extractor.py`** ‚Äî `DPT2Extractor`: `extract_text_from_image()`, `extract_with_layout()` ‚Äî OCR avan√ßado via Landing.AI DPT-2 para documentos complexos
- **`wordcom_toolkit.py`** ‚Äî `WordcomToolkit`: `open_docx()`, `extract_text()`, `extract_tables()` ‚Äî manipula√ß√£o de `.docx` via COM (Windows/pywin32)

---

## `scripts/` ‚Äî Scripts utilit√°rios e UI (execu√ß√£o pontual ou cont√≠nua)

- **`app.py`** ‚Äî UI Streamlit (porta 8501): aba "üîç Consulta" (busca RAG via pipeline ass√≠ncrono de 6 est√°gios com progress bar) e aba "üì• Pipeline Seletivo" (lista reuni√µes TL:DV, multiselect, toggle force_clean, polling de job); consome FastAPI em `localhost:8000`
- **`run_full_pipeline.py`** ‚Äî Pipeline completo via CLI: ingestion TL:DV ‚Üí indexa√ß√£o ChromaDB ‚Üí valida√ß√£o; flags `--force-clean`, `--skip-ingestion`, `--skip-indexing`; relat√≥rio final com estat√≠sticas
- **`run_select_pipeline.py`** ‚Äî Pipeline seletivo via CLI: listagem interativa de reuni√µes ‚Üí sele√ß√£o por √≠ndice/lista/intervalo ‚Üí ingestion ‚Üí indexa√ß√£o ‚Üí relat√≥rio; flag `--force-clean`
- **`auto_init.py`** ‚Äî Auto-gera√ß√£o de `__init__.py` em `src/` (hook de pre-commit do template ‚Äî n√£o modificar)

---

## `data/` ‚Äî Dados persistidos (exclu√≠do do controle de vers√£o via `.gitignore`)

- **`sqlite_db/`** ‚Äî Banco SQLite `hashes.db` gerado pelo `hash_manager`: rastreia arquivos j√° processados por hash de conte√∫do
- **`vector_db/`** ‚Äî Base ChromaDB persistida: embeddings e metadados dos chunks de transcri√ß√µes KT indexadas
- **`transcriptions/`** ‚Äî JSONs consolidados de reuni√µes TL:DV no formato aninhado (`metadata` + `transcript` + `highlights`); subpasta **`chunks/`** com TXTs de auditoria por chunk indexado

---

## `tests/` ‚Äî Testes automatizados

- **`conftest.py`** ‚Äî Fixtures globais: `require_redis` (skip autom√°tico se Redis indispon√≠vel), diret√≥rios tempor√°rios para isolamento de testes
- **`test_kt_ingestion.py`** ‚Äî Testes unit√°rios do dom√≠nio kt_ingestion: TLDVClient, SmartMeetingProcessor, JSONConsolidator
- **`test_kt_indexing.py`** ‚Äî Testes unit√°rios do dom√≠nio kt_indexing: IndexingEngine, ChromaDBStore, utils e normaliza√ß√£o de slugs
- **`test_kt_search.py`** ‚Äî Testes unit√°rios do dom√≠nio kt_search: SearchEngine e componentes individuais do pipeline RAG
- **`test_kt_search_pipeline.py`** ‚Äî Testes de integra√ß√£o do pipeline RAG completo (est√°gios encadeados)
- **`test_search_response_builder.py`** ‚Äî 35 testes do SearchResponseBuilder (including available_clients din√¢mico)
- **`test_search_formatters.py`** ‚Äî 32 testes dos formatadores de busca (92% cobertura)
- **`test_search_cli.py`** ‚Äî 25 testes da search CLI (94% cobertura)
- **`test_search_logging.py`** ‚Äî Testes do PipelineLogger
- **`test_query_type_detector.py`** ‚Äî 37 testes do QueryTypeDetector (detect_specific_kt_analysis)
- **`test_insight_processors.py`** ‚Äî Testes dos processadores de insights
- **`test_insights_prompts.py`** ‚Äî 21 testes dos insights prompts (100% cobertura)
- **`test_smoke.py`** ‚Äî Smoke tests (`@pytest.mark.smoke`): FastAPI importa, Redis conecta, ARQ worker configurado, health endpoint responde 200
- **`test_e2e.py`** ‚Äî E2E tests (`@pytest.mark.e2e`): fluxos completos de busca e indexa√ß√£o com stack real

---

## Raiz do projeto

- **`pyproject.toml`** ‚Äî Depend√™ncias (uv), configura√ß√£o de ruff (lint/format), mypy (type check estrito), pytest (`pythonpath=["."]`, markers `smoke` e `e2e`, coverage em `src/`)
- **`.env.example`** ‚Äî Template de vari√°veis de ambiente com instru√ß√µes para cada chave (REDIS_HOST, OPENAI_API_KEY, TLDV_API_KEY, etc.)
- **`.pre-commit-config.yaml`** ‚Äî Hooks: auto-init (`__init__.py`), validate-structure (pastas obrigat√≥rias), ruff check, ruff format, mypy
- **`CLAUDE.md`** ‚Äî Instru√ß√µes do projeto para Claude Code: arquitetura, padr√µes de c√≥digo, exception handling, comandos e CLAUDEs especializados
